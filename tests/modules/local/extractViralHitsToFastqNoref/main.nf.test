nextflow_process {

    name "Test process EXTRACT_VIRAL_HITS_TO_FASTQ_NOREF_LABELED"
    script "modules/local/extractViralHitsToFastqNoref/main.nf"
    process "EXTRACT_VIRAL_HITS_TO_FASTQ_NOREF_LABELED"
    tag "module"
    tag "extract_viral_hits_to_fastq_noref_labeled"

    test("Should run correctly on interleaved data and preserve entries") {
        tag "interleaved"
        tag "expect_success"
        config "tests/configs/run.config"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                process {
                    '''
                    input[0] = "${projectDir}/test-data/samplesheet.csv"
                    input[1] = "illumina"
                    input[2] = false
                    '''
                }
            }
            run("EXTRACT_VIRAL_READS_SHORT", alias: "EXTRACT_VIRAL_READS_SHORT") {
                script "subworkflows/local/extractViralReadsShort/main.nf"
                process {
                    '''
                    def short_params = [
                        aln_score_threshold: params.bt2_score_threshold,
                        adapter_path: params.adapters,
                        cutadapt_error_rate: params.cutadapt_error_rate,
                        min_kmer_hits: "1",
                        k: "24",
                        bbduk_suffix: "viral",
                        taxid_artificial: "81077"
                    ]
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    input[1] = params.ref_dir
                    input[2] = short_params
                    '''
                }
            }
        }
        when {
            params {}
            process {
                '''
                input[0] = Channel.of("test").combine(EXTRACT_VIRAL_READS_SHORT.out.hits_final)
                input[1] = false
                '''
            }
        }
        then {
            // Should run without failures
            assert process.success
            // Output should preserve read count
            def tab_in = path(process.out.input[0][1]).csv(sep: "\t", decompress: true)
            def fastq_out = path(process.out.output[0][1]).fastq
            def reads_in = tab_in.rowCount
            def reads_out = fastq_out.readNames.size()
            assert reads_in * 2 == reads_out
            // Read IDs and sequences should match
            def quals_out = fastq_out.qualityScores
            def seqs_out = fastq_out.sequences
            def seq_fwd
            def seq_rev
            for (int i = 0; i < reads_in; i++) {
                assert tab_in.columns["seq_id"][i]+" 1" == fastq_out.readNames[2*i]
                assert tab_in.columns["seq_id"][i]+" 2" == fastq_out.readNames[2*i+1]
                seq_fwd = tab_in.columns["query_seq"][i]
                seq_rev = tab_in.columns["query_seq_rev"][i]
                if (seq_fwd == "") {
                    assert seqs_out[2*i] == "N"
                    assert quals_out[2*i] == "!"
                } else {
                    assert seqs_out[2*i] == seq_fwd
                    assert quals_out[2*i] == tab_in.columns["query_qual"][i]
                }
                if (seq_rev == "") {
                    assert seqs_out[2*i+1] == "N"
                    assert quals_out[2*i+1] == "!"
                } else {
                    assert seqs_out[2*i+1] == seq_rev
                    assert quals_out[2*i+1] == tab_in.columns["query_qual_rev"][i]
                }
            }
        }
    }

    test("Should run correctly on single-end data and preserve entries") {
        tag "single_end"
        tag "expect_success"
        config "tests/configs/run.config"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                process {
                    '''
                    input[0] = "${projectDir}/test-data/ont-samplesheet.csv"
                    input[1] = "ont"
                    input[2] = false
                    '''
                }
            }
            run("EXTRACT_VIRAL_READS_ONT", alias: "EXTRACT_VIRAL_READS_ONT") {
                script "subworkflows/local/extractViralReadsONT/main.nf"
                process {
                    '''
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    input[1] = params.ref_dir
                    input[2] = "81077"
                    '''
                }
            }
        }
        when {
            params {}
            process {
                '''
                input[0] = Channel.of("test").combine(EXTRACT_VIRAL_READS_ONT.out.hits_final)
                input[1] = false
                '''
            }
        }
        then {
            // Should run without failures
            assert process.success
            // Output should preserve read count
            def tab_in = path(process.out.input[0][1]).csv(sep: "\t", decompress: true)
            def fastq_out = path(process.out.output[0][1]).fastq
            def reads_in = tab_in.rowCount
            def reads_out = fastq_out.readNames.size()
            assert reads_in == reads_out
            // Read IDs and sequences should match
            def quals_out = fastq_out.qualityScores
            def seqs_out = fastq_out.sequences
            def seq_fwd
            def seq_rev
            for (int i = 0; i < reads_in; i++) {
                assert tab_in.columns["seq_id"][i]+" 1" == fastq_out.readNames[i]
                assert seqs_out[i] == tab_in.columns["query_seq"][i]
                assert quals_out[i] == tab_in.columns["query_qual"][i]
            }
        }
    }
}
