nextflow_process {

    name "Test process SUMMARIZE_BBMERGE_STREAMED"
    script "modules/local/summarizeBBMerge/main.nf"
    process "SUMMARIZE_BBMERGE_STREAMED"
    config "tests/run.config"

    setup {
        run("LOAD_SAMPLESHEET") {
            script "subworkflows/local/loadSampleSheet/main.nf"
            process {
                """
                input[0] = "${projectDir}/test-data/samplesheet.csv"
                input[1] = false
                input[2] = false
                """
            }
        }
        run("INTERLEAVE_FASTQ") {
            script "modules/local/interleaveFastq/main.nf"
            process {
                """
                input[0] = LOAD_SAMPLESHEET.out.samplesheet
                """
            }
        }
        run("BBMERGE_STREAMED") {
            script "modules/local/bbmerge/main.nf"
            process {
                """
                input[0] = INTERLEAVE_FASTQ.out.output
                """
            }
        }
    }

    test("Should run without failures and read counts should match") {
        when {
            params {}
            process {
                '''
                input[0] = BBMERGE_STREAMED.out.reads
                '''
            }
        }
        then {
            // Should run without failures
            assert process.success
            // Output should have expected dimensions
            def countGzipLines = { file -> path(file).linesGzip.size() }
            def input_reads = countGzipLines(process.out.input[0][1]) / 4
            def tab_out = path(process.out.summary[0][1]).csv(sep: "\t", decompress: true)
            assert tab_out.columnCount == 2
            assert tab_out.columnNames == ["seq_id", "bbmerge_frag_length"]
            assert tab_out.rowCount == input_reads
            // TODO: Process input fastq directly using available plugins
        }
    }
}
