nextflow_workflow {

    name "Test workflow MARK_VIRAL_DUPLICATES"
    script "subworkflows/local/markViralDuplicates/main.nf"
    workflow "MARK_VIRAL_DUPLICATES"
    config "tests/configs/run.config"
    tag "subworkflow"
    tag "downstream"
    tag "mark_viral_duplicates"

    setup {
        run("LOAD_DOWNSTREAM_DATA") {
            script "subworkflows/local/loadDownstreamData/main.nf"
            process {
                """
                input[0] = "${projectDir}/test-data/downstream/input_file.csv"
                """
            }
        }
        run("PREPARE_GROUP_TSVS") {
            script "subworkflows/local/prepareGroupTsvs/main.nf"
            process {
                '''
                input[0] = LOAD_DOWNSTREAM_DATA.out.input
                '''
            }
        }
    }

    test("Should run without failures (deviation = 1)") {
        tag "expect_success"
        when {
            params {
                deviation = 1
            }
            workflow {
                '''
                input[0] = PREPARE_GROUP_TSVS.out.groups
                input[1] = params.deviation
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Output should have expected dimensions
            def tab_in = path(workflow.out.test_in[0][1]).csv(sep: "\t", decompress: true)
            def tab_out = path(workflow.out.dup[0][1]).csv(sep: "\t", decompress: true)
            def tab_meta = path(workflow.out.dup[0][2]).csv(sep: "\t", decompress: true)
            assert tab_out.rowCount == tab_in.rowCount
            assert tab_out.columnCount == tab_in.columnCount + 1
            // Output should have expected headers
            assert tab_out.columnNames == tab_in.columnNames + ["prim_align_dup_exemplar"]
            assert tab_meta.columnNames == ["prim_align_genome_id_all", "prim_align_dup_exemplar", "prim_align_dup_count", "prim_align_dup_pairwise_match_frac"]
            // Output should contain expected sequence IDs
            assert tab_in.columns["seq_id"].toSorted() == tab_out.columns["seq_id"].toSorted()
            def line_mapping = tab_out.columns["seq_id"].collect{ element -> tab_in.columns["seq_id"].indexOf(element) }
            // Old columns should be unchanged
            for (c in tab_in.columnNames) {
                assert tab_out.columns[c] == line_mapping.collect{ idx -> tab_in.columns[c][idx] }
            }
            // Output stats should be consistent (not checking correctness here)
            for (r in tab_meta.rows) {
                def exemplar = r["prim_align_dup_exemplar"]
                assert exemplar in tab_out.columns["seq_id"] // Exemplar should be a real read
                assert r["prim_align_dup_count"] == tab_out.columns["prim_align_dup_exemplar"].count(exemplar) // Dup counts should match exemplar assignments
            }
            assert tab_meta.columns["prim_align_dup_count"].sum() == tab_out.rowCount
        }
    }

    test("Should run without failures (deviation = 2)") {
        tag "expect_success"
        when {
            params {
                deviation = 2
            }
            workflow {
                '''
                input[0] = PREPARE_GROUP_TSVS.out.groups
                input[1] = params.deviation
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Output should have expected dimensions
            def tab_in = path(workflow.out.test_in[0][1]).csv(sep: "\t", decompress: true)
            def tab_out = path(workflow.out.dup[0][1]).csv(sep: "\t", decompress: true)
            def tab_meta = path(workflow.out.dup[0][2]).csv(sep: "\t", decompress: true)
            assert tab_out.rowCount == tab_in.rowCount
            assert tab_out.columnCount == tab_in.columnCount + 1
            // Output should have expected headers
            assert tab_out.columnNames == tab_in.columnNames + ["prim_align_dup_exemplar"]
            assert tab_meta.columnNames == ["prim_align_genome_id_all", "prim_align_dup_exemplar", "prim_align_dup_count", "prim_align_dup_pairwise_match_frac"]
            // Output should contain expected sequence IDs
            assert tab_in.columns["seq_id"].toSorted() == tab_out.columns["seq_id"].toSorted()
            def line_mapping = tab_out.columns["seq_id"].collect{ element -> tab_in.columns["seq_id"].indexOf(element) }
            // Old columns should be unchanged
            for (c in tab_in.columnNames) {
                assert tab_out.columns[c] == line_mapping.collect{ idx -> tab_in.columns[c][idx] }
            }
            // Output stats should be consistent (not checking correctness here)
            for (r in tab_meta.rows) {
                def exemplar = r["prim_align_dup_exemplar"]
                assert exemplar in tab_out.columns["seq_id"] // Exemplar should be a real read
                assert r["prim_align_dup_count"] == tab_out.columns["prim_align_dup_exemplar"].count(exemplar) // Dup counts should match exemplar assignments
            }
            assert tab_meta.columns["prim_align_dup_count"].sum() == tab_out.rowCount
        }
    }

    test("Should run without failures (deviation = 0)") {
        tag "expect_success"
        when {
            params {
                deviation = 0
            }
            workflow {
                '''
                input[0] = PREPARE_GROUP_TSVS.out.groups
                input[1] = params.deviation
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Output should have expected dimensions
            def tab_in = path(workflow.out.test_in[0][1]).csv(sep: "\t", decompress: true)
            def tab_out = path(workflow.out.dup[0][1]).csv(sep: "\t", decompress: true)
            def tab_meta = path(workflow.out.dup[0][2]).csv(sep: "\t", decompress: true)
            assert tab_out.rowCount == tab_in.rowCount
            assert tab_out.columnCount == tab_in.columnCount + 1
            // Output should have expected headers
            assert tab_out.columnNames == tab_in.columnNames + ["prim_align_dup_exemplar"]
            assert tab_meta.columnNames == ["prim_align_genome_id_all", "prim_align_dup_exemplar", "prim_align_dup_count", "prim_align_dup_pairwise_match_frac"]
            // Output should contain expected sequence IDs
            assert tab_in.columns["seq_id"].toSorted() == tab_out.columns["seq_id"].toSorted()
            def line_mapping = tab_out.columns["seq_id"].collect{ element -> tab_in.columns["seq_id"].indexOf(element) }
            // Old columns should be unchanged
            for (c in tab_in.columnNames) {
                assert tab_out.columns[c] == line_mapping.collect{ idx -> tab_in.columns[c][idx] }
            }
            // Output stats should be consistent (not checking correctness here)
            for (r in tab_meta.rows) {
                def exemplar = r["prim_align_dup_exemplar"]
                assert exemplar in tab_out.columns["seq_id"] // Exemplar should be a real read
                assert r["prim_align_dup_count"] == tab_out.columns["prim_align_dup_exemplar"].count(exemplar) // Dup counts should match exemplar assignments
            }
            assert tab_meta.columns["prim_align_dup_count"].sum() == tab_out.rowCount
        }
    }

}
