nextflow_workflow {

    name "Test workflow PREPARE_GROUP_TSVS"
    script "subworkflows/local/prepareGroupTsvs/main.nf"
    workflow "PREPARE_GROUP_TSVS"
    config "tests/run.config"
    tag "subworkflow"
    tag "downstream"
    tag "prepare_group_tsvs"

    setup {
        run("LOAD_DOWNSTREAM_DATA") {
            script "subworkflows/local/loadDownstreamData/main.nf"
            process {
                """
                input[0] = "${projectDir}/test-data/downstream/input_file.csv"
                """
            }
        }
        run("COPY_FILE", alias: "COPY_HITS") {
            script "modules/local/copyFile/main.nf"
            process {
                '''
                input[0] = LOAD_DOWNSTREAM_DATA.out.input.map{ label, hits, groups -> tuple(label, hits) }
                input[1] = "test_hits.tsv.gz"
                '''
            }
        }
        run("COPY_FILE", alias: "COPY_GROUPS") {
            script "modules/local/copyFile/main.nf"
            process {
                '''
                input[0] = LOAD_DOWNSTREAM_DATA.out.input.map{ label, hits, groups -> tuple(label, groups) }
                input[1] = "test_groups.tsv"
                '''
            }
        }
    }

    test("Should run without failures") {
        tag "expect_success"
        when {
            params {
            }
            workflow {
                '''
                input[0] = COPY_HITS.out.combine(COPY_GROUPS.out, by: 0)
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Output of join should have expected dimensions
            def input_tabs = workflow.out.test_in.collect{path(it[1]).csv(sep: "\t", decompress: true)}
            def group_tabs = workflow.out.test_in.collect{path(it[2]).csv(sep: "\t")}
            def output_tabs = workflow.out.test_join.collect{path(it[1]).csv(sep: "\t", decompress: true)}
            assert input_tabs.size() == group_tabs.size()
            assert input_tabs.size() == output_tabs.size()
            for (int i=0; i < input_tabs.size(); i++){
                assert input_tabs[i].rowCount == output_tabs[i].rowCount
                assert input_tabs[i].columnCount + group_tabs[i].columnCount - 1 == output_tabs[i].columnCount
            }
            // Partitioning should have no effect (only one sample per dataset)
            def part_tabs = workflow.out.test_part.collect{path(it[1]).csv(sep: "\t", decompress: true)}
            for (int i=0; i < input_tabs.size(); i++){
                assertTableEquals output_tabs[i], part_tabs[i]
            }
        }
    }
}
