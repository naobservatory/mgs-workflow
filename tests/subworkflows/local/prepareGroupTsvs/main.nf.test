nextflow_workflow {

    name "Test workflow PREPARE_GROUP_TSVS"
    script "subworkflows/local/prepareGroupTsvs/main.nf"
    workflow "PREPARE_GROUP_TSVS"
    config "tests/configs/run.config"
    tag "subworkflow"
    tag "downstream"
    tag "prepare_group_tsvs"

    setup {
        run("LOAD_DOWNSTREAM_DATA") {
            script "subworkflows/local/loadDownstreamData/main.nf"
            process {
                """
                input[0] = "${projectDir}/test-data/downstream/input_file.csv"
                """
            }
        }
        run("COPY_FILE", alias: "COPY_HITS") {
            script "modules/local/copyFile/main.nf"
            process {
                '''
                input[0] = LOAD_DOWNSTREAM_DATA.out.input.map{ label, hits, groups -> tuple(label, hits) }
                input[1] = "test_hits.tsv.gz"
                '''
            }
        }
        run("COPY_FILE", alias: "COPY_GROUPS") {
            script "modules/local/copyFile/main.nf"
            process {
                '''
                input[0] = LOAD_DOWNSTREAM_DATA.out.input.map{ label, hits, groups -> tuple(label, groups) }
                input[1] = "test_groups.tsv"
                '''
            }
        }
    }

    test("Should run without failures") {
        tag "expect_success"
        when {
            params {
            }
            workflow {
                '''
                input[0] = COPY_HITS.out.combine(COPY_GROUPS.out, by: 0)
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Output of join should have expected dimensions
            def input_tabs = workflow.out.test_in.collect{path(it[1]).csv(sep: "\t", decompress: true)}
            def group_tabs = workflow.out.test_in.collect{path(it[2]).csv(sep: "\t")}
            def join_tabs = workflow.out.test_join.collect{path(it[1]).csv(sep: "\t", decompress: true)}
            assert input_tabs.size() == group_tabs.size()
            assert input_tabs.size() == join_tabs.size()
            for (int i=0; i < input_tabs.size(); i++){
                assert input_tabs[i].rowCount == join_tabs[i].rowCount
                assert input_tabs[i].columnCount + group_tabs[i].columnCount - 1 == join_tabs[i].columnCount
            }
            // Partitioning should have no effect (only one sample per dataset)
            def part_tabs = workflow.out.test_part.collect{path(it[1]).csv(sep: "\t", decompress: true)}
            for (int i=0; i < input_tabs.size(); i++){
                assertTableEquals join_tabs[i], part_tabs[i]
            }
            // Restructured data should preserve paths
            def paths_pre = []
            for (int i=0; i < input_tabs.size(); i++){
                paths_pre += workflow.out.test_part[i][1]
            }
            def paths_post = []
            for (int i=0; i < workflow.out.test_grps.size(); i++){
                paths_post += workflow.out.test_grps[i][1]
            }
            assert paths_pre.sort() == paths_post.sort()
            // Restructured data should have expected structure
            def groups = []
            for (int i=0; i < group_tabs.size(); i++){
                groups += group_tabs[i].columns["group"]
            }
            groups = groups.unique().sort()
            assert groups.size() == workflow.out.test_grps.size()
            // Each restructured group should have expected size
            def group_sizes = groups.collect{0}
            for (int i=0; i < groups.size(); i++){
                for (t in group_tabs) {
                    if (groups[i] in t.columns["group"]){
                        group_sizes[i] += 1
                    }
                }
                assert group_sizes[i] == workflow.out.test_grps[i][1].size()
            }
            // Final output should correctly concatenate restructured groups while preserving row count
            def output_tabs = workflow.out.groups.collect{path(it[1]).csv(sep: "\t", decompress: true)}
            assert output_tabs.size() < input_tabs.size()
            assert output_tabs.collect{it.rowCount}.sum() == input_tabs.collect{it.rowCount}.sum()
        }
    }
}
