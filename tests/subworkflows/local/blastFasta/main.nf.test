def checkGzipSorted = { file,key -> ["bash", "-c", "zcat " + file + " | sort -C " + key + " && printf 1 || printf 0"].execute().text.trim() as Integer }

nextflow_workflow {

    name "Test subworkflow BLAST_FASTA"
    script "subworkflows/local/blastFasta/main.nf"
    workflow "BLAST_FASTA"
    tag "subworkflow"
    tag "blast_fasta"

    test("Should run without failures on paired (interleaved) data") {
        tag "expect_success"
        tag "interleaved"
        config "tests/configs/run.config"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                process {
                    """
                    input[0] = "${projectDir}/test-data/samplesheet.csv"
                    input[1] = "illumina"
                    input[2] = false
                    """
                }
            }
            run("INTERLEAVE_FASTQ") {
                script "modules/local/interleaveFastq/main.nf"
                process {
                    '''
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    '''
                }
            }
            run("CONVERT_FASTQ_FASTA") {
                script "modules/local/convertFastqFasta/main.nf"
                process {
                    '''
                    input[0] = INTERLEAVE_FASTQ.out.output
                    '''
                }
            }
        }
        when {
            params {
                max_rank = 5
                min_frac = 0.9
                perc_id = 60
                qcov_hsp_perc = 30
            }
            workflow {
                '''
                input[0] = CONVERT_FASTQ_FASTA.out.output
                input[1] = "${params.ref_dir}/results/${params.blast_db_prefix}"
                input[2] = params.blast_db_prefix
                input[3] = params.perc_id
                input[4] = params.qcov_hsp_perc
                input[5] = params.max_rank
                input[6] = params.min_frac
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Output should be sorted by query ID (ascending) and bitscore (descending)
            def sort_str =  "-t\$\'\\t\' -k1,1 -k7,7nr"
            def output_sorted = checkGzipSorted(workflow.out.blast[0][1], sort_str)
            // Output should have expected columns
            def tab_out = path(workflow.out.blast[0][1]).csv(sep: "\t", decompress: true)
            def cols_out_exp = ["qseqid", "sseqid", "sgi", "staxid", "qlen", "evalue",
                         "bitscore", "qcovs", "length", "pident", "mismatch",
                         "gapopen", "sstrand", "qstart", "qend", "sstart", "send",
                         "bitscore_rank_dense", "bitscore_fraction"]
            assert tab_out.columnNames == cols_out_exp
            // All output lines should meet score and/or rank criteria
            def meets_rank = false
            def meets_frac = false
            for (r in tab_out.rows){
                meets_rank = r["bitscore_rank_dense"] <= params.max_rank
                meets_frac = r["bitscore_fraction"] >= params.min_frac
                assert meets_rank || meets_frac
            }
            // Every query/subject combination should be unique
            def key_paste = []
            for (int i = 0; i < tab_out.rowCount; i++){
                key_paste += tab_out.columns["qseqid"][i] + "\t" + tab_out.columns["sseqid"][i]
            }
            def rows_exp = key_paste.toSet().size()
            assert tab_out.rowCount == rows_exp
            // All seq IDs should be in input
            def fasta_in = path(workflow.out.query[0][1]).fasta
            def ids_in = fasta_in.keySet().collect{ it.tokenize(" ")[0] }.toSet()
            def ids_out = tab_out.columns["qseqid"].toSet()
            assert ids_in.containsAll(ids_out)
        }
    }

    test("Should run without failures on single-end data") {
        tag "expect_success"
        tag "single_end"
        config "tests/configs/run.config"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                process {
                    """
                    input[0] = "${projectDir}/test-data/single-end-samplesheet.csv"
                    input[1] = "illumina"
                    input[2] = true
                    """
                }
            }
            run("COPY_FILE") {
                script "modules/local/copyFile/main.nf"
                process {
                    '''
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    input[1] = "input.fastq.gz"
                    '''
                }
            }
            run("CONVERT_FASTQ_FASTA") {
                script "modules/local/convertFastqFasta/main.nf"
                process {
                    '''
                    input[0] = COPY_FILE.out
                    '''
                }
            }
        }
        when {
            params {
                max_rank = 5
                min_frac = 0.9
                perc_id = 60
                qcov_hsp_perc = 30
            }
            workflow {
                '''
                input[0] = CONVERT_FASTQ_FASTA.out.output
                input[1] = "${params.ref_dir}/results/${params.blast_db_prefix}"
                input[2] = params.blast_db_prefix
                input[3] = params.perc_id
                input[4] = params.qcov_hsp_perc
                input[5] = params.max_rank
                input[6] = params.min_frac
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Output should be sorted by query ID (ascending) and bitscore (descending)
            def sort_str =  "-t\$\'\\t\' -k1,1 -k7,7nr"
            def output_sorted = checkGzipSorted(workflow.out.blast[0][1], sort_str)
            // Output should have expected columns
            def tab_out = path(workflow.out.blast[0][1]).csv(sep: "\t", decompress: true)
            def cols_out_exp = ["qseqid", "sseqid", "sgi", "staxid", "qlen", "evalue",
                         "bitscore", "qcovs", "length", "pident", "mismatch",
                         "gapopen", "sstrand", "qstart", "qend", "sstart", "send",
                         "bitscore_rank_dense", "bitscore_fraction"]
            assert tab_out.columnNames == cols_out_exp
            // All output lines should meet score and/or rank criteria
            def meets_rank = false
            def meets_frac = false
            for (r in tab_out.rows){
                meets_rank = r["bitscore_rank_dense"] <= params.max_rank
                meets_frac = r["bitscore_fraction"] >= params.min_frac
                assert meets_rank || meets_frac
            }
            // Every query/subject combination should be unique
            def key_paste = []
            for (int i = 0; i < tab_out.rowCount; i++){
                key_paste += tab_out.columns["qseqid"][i] + "\t" + tab_out.columns["sseqid"][i]
            }
            def rows_exp = key_paste.toSet().size()
            assert tab_out.rowCount == rows_exp
            // All seq IDs should be in input
            def fasta_in = path(workflow.out.query[0][1]).fasta
            def ids_in = fasta_in.keySet().collect{ it.tokenize(" ")[0] }.toSet()
            def ids_out = tab_out.columns["qseqid"].toSet()
            assert ids_in.containsAll(ids_out)
        }
    }

    test("Should run without failures on ONT data") {
        tag "expect_success"
        tag "ont"
        config "tests/configs/run_ont.config"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                process {
                    """
                    input[0] = "${projectDir}/test-data/ont-samplesheet.csv"
                    input[1] = "ont"
                    input[2] = false
                    """
                }
            }
            run("COPY_FILE") {
                script "modules/local/copyFile/main.nf"
                process {
                    '''
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    input[1] = "input.fastq.gz"
                    '''
                }
            }
            run("CONVERT_FASTQ_FASTA") {
                script "modules/local/convertFastqFasta/main.nf"
                process {
                    '''
                    input[0] = COPY_FILE.out
                    '''
                }
            }
        }
        when {
            params {
                max_rank = 5
                min_frac = 0.9
                perc_id = 0
                qcov_hsp_perc = 0
            }
            workflow {
                '''
                input[0] = CONVERT_FASTQ_FASTA.out.output
                input[1] = "${params.ref_dir}/results/${params.blast_db_prefix}"
                input[2] = params.blast_db_prefix
                input[3] = params.perc_id
                input[4] = params.qcov_hsp_perc
                input[5] = params.max_rank
                input[6] = params.min_frac
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Output should be sorted by query ID (ascending) and bitscore (descending)
            def sort_str =  "-t\$\'\\t\' -k1,1 -k7,7nr"
            def output_sorted = checkGzipSorted(workflow.out.blast[0][1], sort_str)
            // Output should have expected columns
            def tab_out = path(workflow.out.blast[0][1]).csv(sep: "\t", decompress: true)
            def cols_out_exp = ["qseqid", "sseqid", "sgi", "staxid", "qlen", "evalue",
                         "bitscore", "qcovs", "length", "pident", "mismatch",
                         "gapopen", "sstrand", "qstart", "qend", "sstart", "send",
                         "bitscore_rank_dense", "bitscore_fraction"]
            assert tab_out.columnNames == cols_out_exp
            // All output lines should meet score and/or rank criteria
            def meets_rank = false
            def meets_frac = false
            for (r in tab_out.rows){
                meets_rank = r["bitscore_rank_dense"] <= params.max_rank
                meets_frac = r["bitscore_fraction"] >= params.min_frac
                assert meets_rank || meets_frac
            }
            // Every query/subject combination should be unique
            def key_paste = []
            for (int i = 0; i < tab_out.rowCount; i++){
                key_paste += tab_out.columns["qseqid"][i] + "\t" + tab_out.columns["sseqid"][i]
            }
            def rows_exp = key_paste.toSet().size()
            assert tab_out.rowCount == rows_exp
            // All seq IDs should be in input
            def fasta_in = path(workflow.out.query[0][1]).fasta
            def ids_in = fasta_in.keySet().collect{ it.tokenize(" ")[0] }.toSet()
            def ids_out = tab_out.columns["qseqid"].toSet()
            assert ids_in.containsAll(ids_out)
        }
    }

}
