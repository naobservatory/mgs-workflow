def checkGzipSorted = { file,key -> ["bash", "-c", "zcat " + file + " | sort -C " + key + " && printf 1 || printf 0"].execute().text.trim() as Integer }

nextflow_workflow {

    name "Test workflow BLAST_VIRAL"
    script "subworkflows/local/blastViral/main.nf"
    workflow "BLAST_VIRAL"
    tag "subworkflow"
    tag "blast_viral"

    test("Should run without failures on paired (interleaved) data") {
        tag "expect_success"
        tag "interleaved"
        config "tests/run.config"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                process {
                    """
                    input[0] = "${projectDir}/test-data/samplesheet.csv"
                    input[1] = false
                    """
                }
            }
            run("INTERLEAVE_FASTQ") {
                script "modules/local/interleaveFastq/main.nf"
                process {
                    '''
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    '''
                }
            }
        }
        when {
            params {
                max_rank = 5
                min_frac = 0.9
                blast_frac = 0.95
            }
            workflow {
                '''
                input[0] = INTERLEAVE_FASTQ.out.output.collect{it[1]}
                input[1] = "${params.ref_dir}/results/${params.blast_db_prefix}"
                input[2] = params.blast_db_prefix
                input[3] = params.blast_frac
                input[4] = params.max_rank
                input[5] = params.min_frac
                input[6] = ""
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Output should be sorted by query ID (ascending) and bitscore (descending)
            def sort_str =  "-t\$\'\\t\' -k1,1 -k7,7nr"
            def output_sorted = checkGzipSorted(workflow.out.blast_subset[0][1], sort_str)
            // Output should have expected columns
            def tab_out = path(workflow.out.blast_subset[0][1]).csv(sep: "\t", decompress: true)
            def cols_out_exp = ["qseqid", "sseqid", "sgi", "staxid", "qlen", "evalue",
                         "bitscore", "qcovs", "length", "pident", "mismatch",
                         "gapopen", "sstrand", "qstart", "qend", "sstart", "send",
                         "bitscore_rank_dense", "bitscore_fraction"]
            assert tab_out.columnNames == cols_out_exp
            // All output lines should meet score and/or rank criteria
            def meets_rank = false
            def meets_frac = false
            for (r in tab_out.rows){
                meets_rank = r["bitscore_rank_dense"] <= params.max_rank
                meets_frac = r["bitscore_fraction"] >= params.min_frac
                assert meets_rank || meets_frac
            }
            // Every query/subject combination should be unique
            def key_paste = []
            for (int i = 0; i < tab_out.rowCount; i++){
                key_paste += tab_out.columns["qseqid"][i] + "\t" + tab_out.columns["sseqid"][i]
            }
            def rows_exp = key_paste.toSet().size()
            assert tab_out.rowCount == rows_exp
            // All seq IDs should be in input
            def fastq_in = path(workflow.out.test_input[0][1]).fastq
            def ids_in = fastq_in.readNames.collect{ it.tokenize(" ")[0] }.toSet()
            def ids_out = tab_out.columns["qseqid"].toSet()
            for (i in ids_out) {
                assert i in ids_in
            }
        }
    }

    test("Should run without failures on single-end data") {
        tag "expect_success"
        tag "single_end"
        config "tests/run_dev_se.config"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                process {
                    """
                    input[0] = "${projectDir}/test-data/single-end-samplesheet.csv"
                    input[1] = true
                    """
                }
            }
            run("COPY_FILE") {
                script "modules/local/copyFile/main.nf"
                process {
                    '''
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    input[1] = "input.fastq.gz"
                    '''
                }
            }
        }
        when {
            params {
                max_rank = 5
                min_frac = 0.9
            }
            workflow {
                '''
                input[0] = COPY_FILE.out.collect{it[1]}
                input[1] = "${params.ref_dir}/results/${params.blast_db_prefix}"
                input[2] = params.blast_db_prefix
                input[3] = 0.95
                input[4] = params.max_rank
                input[5] = params.min_frac
                input[6] = ""
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Output should be sorted by query ID (ascending) and bitscore (descending)
            def sort_str =  "-t\$\'\\t\' -k1,1 -k7,7nr"
            def output_sorted = checkGzipSorted(workflow.out.blast_subset[0][1], sort_str)
            // Output should have expected columns
            def tab_out = path(workflow.out.blast_subset[0][1]).csv(sep: "\t", decompress: true)
            def cols_out_exp = ["qseqid", "sseqid", "sgi", "staxid", "qlen", "evalue",
                         "bitscore", "qcovs", "length", "pident", "mismatch",
                         "gapopen", "sstrand", "qstart", "qend", "sstart", "send",
                         "bitscore_rank_dense", "bitscore_fraction"]
            assert tab_out.columnNames == cols_out_exp
            // All output lines should meet score and/or rank criteria
            def meets_rank = false
            def meets_frac = false
            for (r in tab_out.rows){
                meets_rank = r["bitscore_rank_dense"] <= params.max_rank
                meets_frac = r["bitscore_fraction"] >= params.min_frac
                assert meets_rank || meets_frac
            }
            // Every query/subject combination should be unique
            def key_paste = []
            for (int i = 0; i < tab_out.rowCount; i++){
                key_paste += tab_out.columns["qseqid"][i] + "\t" + tab_out.columns["sseqid"][i]
            }
            def rows_exp = key_paste.toSet().size()
            assert tab_out.rowCount == rows_exp
            // All seq IDs should be in input
            def fastq_in = path(workflow.out.test_input[0][1]).fastq
            def ids_in = fastq_in.readNames.collect{ it.tokenize(" ")[0] }.toSet()
            def ids_out = tab_out.columns["qseqid"].toSet()
            for (i in ids_out) {
                assert i in ids_in
            }
        }
    }

}
