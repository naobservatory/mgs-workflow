nextflow_workflow {

    name "Test subworkflow RUN_QC"
    script "subworkflows/local/runQc/main.nf"
    workflow "RUN_QC"
    tag "subworkflow"
    tag "run_qc"

    test("Should run without failures on paired (interleaved) data") {
        config "tests/configs/run.config"
        tag "expect_success"
        tag "interleaved"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                workflow {
                    '''
                    input[0] = "${projectDir}/test-data/samplesheet.csv"
                    input[1] = "illumina"
                    input[2] = false
                    '''
                }
            }
            run("SUBSET_TRIM") {
                script "subworkflows/local/subsetTrim/main.nf"
                process {
                    '''
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    input[1] = 49
                    input[2] = params.adapters
                    input[3] = LOAD_SAMPLESHEET.out.single_end
                    input[4] = false
                    input[5] = ""
                    '''
                }
            }
        }
        when {
            params {}
            workflow {
                """
                input[0] = SUBSET_TRIM.out.subset_reads
                input[1] = SUBSET_TRIM.out.trimmed_subset_reads
                input[2] = LOAD_SAMPLESHEET.out.single_end
                """
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Basic stats TSV should have expected structure and content
            def tsv_basic = path(workflow.out.qc_basic[0]).csv(sep: "\t", decompress: true)
            assert tsv_basic.rowCount == 2
            assert tsv_basic.columnCount == 17
            // Other TSVs should have expected structure and content
            def tsv_adapt = path(workflow.out.qc_adapt[0]).csv(sep: "\t", decompress: true)
            assert tsv_adapt.columnCount == 6
            def tsv_qbase = path(workflow.out.qc_qbase[0]).csv(sep: "\t", decompress: true)
            assert tsv_qbase.columnCount == 5
            def tsv_qseqs = path(workflow.out.qc_qseqs[0]).csv(sep: "\t", decompress: true)
            assert tsv_qseqs.columnCount == 5
            def tsv_lengths = path(workflow.out.qc_lengths[0]).csv(sep: "\t", decompress: true)
            assert tsv_lengths.columnCount == 5
        }
    }

    test("Should run without failures on single-end data") {
        config "tests/configs/run.config"
        tag "expect_success"
        tag "single_end"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                workflow {
                    '''
                    input[0] = "${projectDir}/test-data/single-end-samplesheet.csv"
                    input[1] = "illumina"
                    input[2] = true
                    '''
                }
            }
            run("SUBSET_TRIM") {
                script "subworkflows/local/subsetTrim/main.nf"
                process {
                    '''
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    input[1] = 49
                    input[2] = params.adapters
                    input[3] = LOAD_SAMPLESHEET.out.single_end
                    input[4] = false
                    input[5] = ""
                    '''
                }
            }
        }
        when {
            params {}
            workflow {
                """
                input[0] = SUBSET_TRIM.out.subset_reads
                input[1] = SUBSET_TRIM.out.trimmed_subset_reads
                input[2] = LOAD_SAMPLESHEET.out.single_end
                """
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Basic stats TSV should have expected structure and content
            def tsv_basic = path(workflow.out.qc_basic[0]).csv(sep: "\t", decompress: true)
            assert tsv_basic.rowCount == 2
            assert tsv_basic.columnCount == 17
            // Other TSVs should have expected structure and content
            def tsv_adapt = path(workflow.out.qc_adapt[0]).csv(sep: "\t", decompress: true)
            assert tsv_adapt.columnCount == 6
            def tsv_qbase = path(workflow.out.qc_qbase[0]).csv(sep: "\t", decompress: true)
            assert tsv_qbase.columnCount == 5
            def tsv_qseqs = path(workflow.out.qc_qseqs[0]).csv(sep: "\t", decompress: true)
            assert tsv_qseqs.columnCount == 5
            def tsv_lengths = path(workflow.out.qc_lengths[0]).csv(sep: "\t", decompress: true)
            assert tsv_lengths.columnCount == 5
        }
    }
    
    test("Should handle empty input files properly") {
        config "tests/configs/run.config"
        tag "expect_success"
        tag "empty_input"
        setup {
            run("GZIP_FILE") {
                script "modules/local/gzipFile/main.nf"
                process {
                    """
                    input[0] = Channel.of("empty_sample").combine(Channel.of("${projectDir}/test-data/toy-data/empty_file.txt"))
                    """
                }
            }
        }
        when {
            params {}
            workflow {
                """
                input[0] = GZIP_FILE.out
                input[1] = GZIP_FILE.out
                input[2] = Channel.of(true)
                """
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Basic stats TSV should have expected structure and content
            def tsv_basic = path(workflow.out.qc_basic[0]).csv(sep: "\t", decompress: true)
            assert tsv_basic.rowCount == 2
            assert tsv_basic.columnCount == 15
            // Lengths TSV should have expected structure and content
            def tsv_lengths = path(workflow.out.qc_lengths[0]).csv(sep: "\t", decompress: true)
            assert tsv_lengths.rowCount == 2
            assert tsv_lengths.columnCount == 5
            // Other TSVs should have expected structure and content
            def tsv_adapt = path(workflow.out.qc_adapt[0]).linesGzip
            assert tsv_adapt.size() == 1
            assert tsv_adapt[0].split("\t").size() == 6
            def tsv_qbase = path(workflow.out.qc_qbase[0]).linesGzip
            assert tsv_qbase.size() == 1
            assert tsv_qbase[0].split("\t").size() == 5
            def tsv_qseqs = path(workflow.out.qc_qseqs[0]).linesGzip
            assert tsv_qseqs.size() == 1
            assert tsv_qseqs[0].split("\t").size() == 5
        }
    }
}
