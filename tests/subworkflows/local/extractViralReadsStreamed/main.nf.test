// Helper function: manual table filtering
def filter_tab = { tab_in, threshold -> csv(tab_in.table.where(
    tab_in.table.intColumn("kraken_assigned_host_virus").isEqualTo(1).or(
        tab_in.table.numberColumn("bowtie2_length_normalized_score_max").isGreaterThanOrEqualTo(threshold).and(
            tab_in.table.intColumn("kraken_assigned_host_virus").isEqualTo(2).or(
                tab_in.table.booleanColumn("kraken_classified").isFalse()))))) }

nextflow_workflow {

    name "Test workflow EXTRACT_VIRAL_READS_STREAMED"
    script "subworkflows/local/extractViralReadsStreamed/main.nf"
    workflow "EXTRACT_VIRAL_READS_STREAMED"
    config "tests/run.config"

    setup {
        run("LOAD_SAMPLESHEET") {
            script "subworkflows/local/loadSampleSheet/main.nf"
            process {
                """
                input[0] = "test-data/samplesheet.csv"
                """
            }
        }
    }

    test("Should run without failures") {
        when {
            params {
                bt2_score_threshold = 20
            }
            workflow {
                '''
                input[0] = LOAD_SAMPLESHEET.out.samplesheet
                input[1] = LOAD_SAMPLESHEET.out.group
                input[2] = params.ref_dir
                input[3] = "${params.ref_dir}/results/kraken_db"
                input[4] = params.bt2_score_threshold
                input[5] = params.adapters
                input[6] = params.host_taxon
                input[7] = "1"
                input[8] = "24"
                input[9] = "viral"
                input[10] = params.quality_encoding
                input[11] = params.fuzzy_match_alignment_duplicates
                input[12] = params.grouping
                input[13] = params.single_end
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Output should have a nonzero number of lines divisible by eight
            // (for an interleaved FASTQ file)
            def countGzipLines = { file -> path(file).linesGzip.size() }
            def test_reads_lines = countGzipLines(workflow.out.test_reads[0][1])
            assert test_reads_lines > 0
            assert test_reads_lines % 8 == 0
            // Processed Kraken output should match lines in test reads
            def test_kraken_tab = path(workflow.out.test_kraken[0][1]).csv(sep: "\t", decompress: true)
            assert test_kraken_tab.rowCount == test_reads_lines / 8
            // Other tabular tests
            def test_bowtie_tab = path(workflow.out.test_bowtie[0][1]).csv(sep: "\t", decompress: true)
            def test_joined_tab = path(workflow.out.test_joined[0][1]).csv(sep: "\t", decompress: true)
            assert test_joined_tab.rowCount == Math.min(test_bowtie_tab.rowCount, test_kraken_tab.rowCount)
            assert test_joined_tab.columnCount == test_bowtie_tab.columnCount + test_kraken_tab.columnCount - 1 + 2
            // Test filtering produced expected results
            def hits_all_tab = path(workflow.out.hits_all[0]).csv(sep: "\t", decompress: true)
            def hits_filtered_tab = path(workflow.out.hits_filtered[0]).csv(sep: "\t", decompress: true)
            assertTableEquals hits_all_tab, test_joined_tab
            assert hits_all_tab.columnNames == hits_filtered_tab.columnNames
            assert hits_all_tab.rowCount >= hits_filtered_tab.rowCount
            def hits_exp_tab = filter_tab(hits_all_tab, params.bt2_score_threshold)
            assert hits_exp_tab.columnNames == hits_filtered_tab.columnNames
            assert hits_exp_tab.rowCount == hits_filtered_tab.rowCount
            assertTableEquals hits_exp_tab, hits_filtered_tab
        }
    }
}
