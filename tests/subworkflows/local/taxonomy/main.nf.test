nextflow_workflow {

    name "Test subworkflow TAXONOMY"
    script "subworkflows/local/taxonomy/main.nf"
    workflow "TAXONOMY"
    tag "subworkflow"
    tag "taxonomy"

    test("Should run without failures on paired (interleaved) input") {
        tag "expect_success"
        tag "interleaved"
        config "tests/run.config"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                process {
                    """
                    input[0] = "${projectDir}/test-data/samplesheet.csv"
                    input[1] = false
                    """
                }
            }
            run("INTERLEAVE_FASTQ") {
                script "modules/local/interleaveFastq/main.nf"
                process {
                    """
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    """
                }
            }
        }
        when {
            params {
            }
            workflow {
                '''
                input[0] = INTERLEAVE_FASTQ.out.output
                input[1] = "${params.ref_dir}/results/kraken_db"
                input[2] = "D"
                input[3] = "5"
                input[4] = false
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Read output should have a nonzero number of lines divisible by four
            def countGzipLines = { file -> path(file).linesGzip.size() }
            def single_read_lines = countGzipLines(workflow.out.single_reads[0][1])
            assert single_read_lines > 0
            assert single_read_lines % 4 == 0
            // Merged read count should equal input read count
            def input_read_lines = countGzipLines(workflow.out.input_reads[0][1])
            assert single_read_lines == input_read_lines / 2
            // Kraken output lines should match input reads
            def kraken_output_lines = countGzipLines(workflow.out.kraken_output[0][1])
            assert kraken_output_lines == single_read_lines / 4
            // Kraken reports should have expected fields
            def kraken_report_tab = path(workflow.out.kraken_reports[0]).csv(sep: "\t", decompress: true)
            def kraken_headers_exp = ["pc_reads_total", "n_reads_clade", "n_reads_direct", "n_minimizers_total", "n_minimizers_distinct", "rank","taxid", "name", "sample"]
            assert kraken_report_tab.columnCount == 9
            assert kraken_report_tab.columnNames == kraken_headers_exp
            // Bracken output should have expected fields
            def bracken_tab = path(workflow.out.bracken[0]).csv(sep: "\t", decompress: true)
            def bracken_headers_exp = ["name", "taxid", "rank", "kraken_assigned_reads", "added_reads", "new_est_reads", "fraction_total_reads", "sample"]
            assert bracken_tab.columnCount == 8
            assert bracken_tab.columnNames == bracken_headers_exp
            // BBMerge summary output should have expected fields
            def bbmerge_tab = path(workflow.out.bbmerge_summary[0][1]).csv(sep: "\t", decompress: true)
            def bbmerge_headers_exp = ["seq_id", "bbmerge_frag_length"]
            assert bbmerge_tab
            assert bbmerge_tab.columnNames == bbmerge_headers_exp
        }
    }

    test("Should run without failures on unpaired input") {
        tag "expect_success"
        tag "single_end"
        config "tests/run_dev_se.config"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                process {
                    """
                    input[0] = "${projectDir}/test-data/single-end-samplesheet.csv"
                    input[1] = true
                    """
                }
            }
            run("COPY_FILE") {
                script "modules/local/copyFile/main.nf"
                process {
                    """
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    input[1] = "input.fastq.gz"
                    """
                }
            }
        }
        when {
            params {}
            workflow {
                '''
                input[0] = COPY_FILE.out
                input[1] = "${params.ref_dir}/results/kraken_db"
                input[2] = "D"
                input[3] = "5"
                input[4] = true
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Read output should have a nonzero number of lines divisible by four
            def countGzipLines = { file -> path(file).linesGzip.size() }
            def single_read_lines = countGzipLines(workflow.out.single_reads[0][1])
            assert single_read_lines > 0
            assert single_read_lines % 4 == 0
            // "Merged" reads should exactly equal input reads
            def input_read_md5 = path(workflow.out.input_reads[0][1]).md5
            def single_read_md5 = path(workflow.out.single_reads[0][1]).md5
            assert single_read_md5 == input_read_md5
            def input_read_lines = countGzipLines(workflow.out.input_reads[0][1])
            assert single_read_lines == input_read_lines
            // Kraken output lines should match input reads
            def kraken_output_lines = countGzipLines(workflow.out.kraken_output[0][1])
            assert kraken_output_lines == single_read_lines / 4
            // Kraken reports should have expected fields
            def kraken_report_tab = path(workflow.out.kraken_reports[0]).csv(sep: "\t", decompress: true)
            def kraken_headers_exp = ["pc_reads_total", "n_reads_clade", "n_reads_direct", "n_minimizers_total", "n_minimizers_distinct", "rank","taxid", "name", "sample"]
            assert kraken_report_tab.columnCount == 9
            assert kraken_report_tab.columnNames == kraken_headers_exp
            // Bracken output should have expected fields
            def bracken_tab = path(workflow.out.bracken[0]).csv(sep: "\t", decompress: true)
            def bracken_headers_exp = ["name", "taxid", "rank", "kraken_assigned_reads", "added_reads", "new_est_reads", "fraction_total_reads", "sample"]
            assert bracken_tab.columnCount == 8
            assert bracken_tab.columnNames == bracken_headers_exp
            // BBMerge summary output should be empty
            assert workflow.out.bbmerge_summary == []
        }
    }
}
