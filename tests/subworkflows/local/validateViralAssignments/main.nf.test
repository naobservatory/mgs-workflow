nextflow_workflow {

    name "Test workflow VALIDATE_VIRAL_ASSIGNMENTS"
    script "subworkflows/local/validateViralAssignments/main.nf"
    workflow "VALIDATE_VIRAL_ASSIGNMENTS"
    config "tests/configs/downstream.config"
    tag "subworkflow"
    tag "downstream"
    tag "validate_viral_assignments"

    setup {
        run("LOAD_DOWNSTREAM_DATA") {
            script "subworkflows/local/loadDownstreamData/main.nf"
            process {
                """
                input[0] = "${projectDir}/test-data/downstream/input_file.csv"
                """
            }
        }
        run("PREPARE_GROUP_TSVS") {
            script "subworkflows/local/prepareGroupTsvs/main.nf"
            process {
                '''
                input[0] = LOAD_DOWNSTREAM_DATA.out.input
                '''
            }
        }
        run("COPY_FILE_BARE") {
            script "modules/local/copyFile/main.nf"
            process {
                '''
                input[0] = "${params.ref_dir}/results/total-virus-db-annotated.tsv.gz"
                input[1] = "virus-db.tsv.gz"
                '''
            }
        }
    }

    test("Should run without failures on valid input data") {
        tag "expect_success"
        when {
            params {
                n_clusters = 10
            }
            workflow {
                '''
                input[0] = PREPARE_GROUP_TSVS.out.groups // groups
                input[1] = COPY_FILE_BARE.out // db
                input[2] = params.validation_cluster_identity // cluster_identity
                input[3] = 15 // cluster_min_len
                input[4] = params.n_clusters // n_clusters
                input[5] = "${params.ref_dir}/results/${params.blast_db_prefix}" // blast_db_dir TODO
                input[6] = params.blast_db_prefix // blast_db_prefix
                input[7] = params.blast_perc_id // perc_id
                input[8] = params.blast_qcov_hsp_perc // qcov_hsp_perc
                input[9] = params.blast_max_rank // blast_max_rank
                input[10] = params.blast_min_frac // blast_min_frac
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Clustering should preserve reads
            def tabs_split = workflow.out.test_split_tsv.collect{path(it[1]).csv(sep: "\t",decompress: true)}
            def tabs_clust = workflow.out.test_cluster_tab.collect{path(it[1]).csv(sep: "\t",decompress: true)}
            assert tabs_split.size() == tabs_clust.size()
            for (int i = 0; i < tabs_split.size(); i++) {
                assert tabs_split[i].rowCount == tabs_clust[i].rowCount
            }
            // Regrouping should work as expected
            def tabs_in = workflow.out.test_in.collect{path(it[1]).csv(sep: "\t",decompress: true)}
            def tabs_regrouped = workflow.out.test_regrouped.collect{path(it[1]).csv(sep: "\t",decompress: true)}
            assert tabs_regrouped.size() == tabs_in.size()
            for (int i=0; i < tabs_regrouped.size(); i++) {
                assert tabs_regrouped[i].rowCount == tabs_in[i].rowCount
                assert tabs_regrouped[i].columns["seq_id"].unique().toSorted() == tabs_in[i].columns["seq_id"].unique().toSorted()
            }
            // Basic BLAST invocation should work as expected
            def blast_db = workflow.out.test_blast_db.collect{path(it[1]).csv(sep: "\t",decompress: true)}
            def blast_query = workflow.out.test_blast_query.collect{path(it[1]).fasta}
            def cluster_fasta = workflow.out.test_reps_fasta.collect{path(it[1]).fasta}
            assert blast_query == cluster_fasta
            assert blast_db.size() == blast_query.size()
            for (int i=0; i < blast_db.size(); i++) {
                if (blast_db[i].rowCount == 0) {
                    continue
                }
                // qseqids should all be in query input
                def ids_in = blast_query[i].keySet().collect{ it.tokenize(" ")[0] }.toSet()
                def ids_out = blast_db[i].columns["qseqid"].toSet()
                assert ids_in.containsAll(ids_out)
            }
        }
    }

}
