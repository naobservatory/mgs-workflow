nextflow_workflow {

    name "Test workflow VALIDATE_VIRAL_ASSIGNMENTS"
    script "subworkflows/local/validateViralAssignments/main.nf"
    workflow "VALIDATE_VIRAL_ASSIGNMENTS"
    config "tests/configs/downstream.config"
    tag "subworkflow"
    tag "downstream"
    tag "validate_viral_assignments"

    setup {
        run("LOAD_DOWNSTREAM_DATA") {
            script "subworkflows/local/loadDownstreamData/main.nf"
            process {
                """
                input[0] = "${projectDir}/test-data/downstream/input_file.csv"
                """
            }
        }
        run("PREPARE_GROUP_TSVS") {
            script "subworkflows/local/prepareGroupTsvs/main.nf"
            process {
                '''
                input[0] = LOAD_DOWNSTREAM_DATA.out.input
                '''
            }
        }
        run("COPY_FILE_BARE") {
            script "modules/local/copyFile/main.nf"
            process {
                '''
                input[0] = "${params.ref_dir}/results/total-virus-db-annotated.tsv.gz"
                input[1] = "virus-db.tsv.gz"
                '''
            }
        }
    }

    test("Should run without failures on valid input data") {
        tag "expect_success"
        when {
            params {
            }
            workflow {
                '''
                input[0] = PREPARE_GROUP_TSVS.out.groups
                input[1] = COPY_FILE_BARE.out
                input[2] = params.validation_cluster_identity
                input[3] = 15
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Sorting should work as expected
            def tabs_in = workflow.out.test_in.collect{path(it[1]).csv(sep: "\t", decompress: true)}
            def tabs_sort = workflow.out.test_sort.collect{path(it[1]).csv(sep: "\t", decompress: true)}
            assert tabs_sort.size() == tabs_in.size()
            for (int i=0; i < tabs_in.size(); i++) {
                assert tabs_sort[i].rowCount == tabs_in[i].rowCount
                assert tabs_sort[i].columnCount == tabs_in[i].columnCount
                assert tabs_sort[i].columns["taxid"].collect{ it.toString() } == tabs_in[i].columns["bowtie2_taxid_best"].collect{ it.toString() }.toSorted()
            }
            // Joined DB should have expected contents
            def tabs_join = workflow.out.test_join.collect{path(it[1]).csv(sep: "\t",decompress: true)}
            def tab_db = path(workflow.out.test_db[0]).csv(sep: "\t", decompress: true)
            assert tabs_join.size() == tabs_sort.size()
            for (int i=0; i < tabs_sort.size(); i++) {
                assert tabs_join[i].rowCount == tabs_sort[i].rowCount
                assert tabs_join[i].columnCount == tabs_sort[i].columnCount + tab_db.columnCount - 1
                for (c in tabs_join[i].columnNames) {
                    if (c in tabs_sort[i].columnNames) {
                        assert tabs_sort[i].columns[c] == tabs_join[i].columns[c]
                    } else {
                        assert c in tab_db.columnNames
                    }
                }
            }
            // Partition should produce expected number of output DBs
            def n_parts_total = 0
            def n_parts_exp
            def n_parts_obs
            for (int i=0; i < tabs_join.size(); i++) {
                n_parts_exp = tabs_join[i].columns["taxid_species"].unique().size()
                n_parts_obs = workflow.out.test_part[i][1].size()
                assert n_parts_exp == n_parts_obs
                n_parts_total += n_parts_obs
            }
            assert workflow.out.test_part_2.size() == n_parts_total
            // FASTQ extraction and merging should work as expected
            def tabs_part_2 = workflow.out.test_part_2.collect{path(it[1]).csv(sep: "\t",decompress: true)}
            def fastqs_interleaved = workflow.out.test_fastq.collect{path(it[1]).fastq}
            def fastqs_merged = workflow.out.test_concat.collect{path(it[1]).fastq}
            for (int i=0; i < tabs_part_2.size(); i++) {
                assert tabs_part_2[i].rowCount == fastqs_interleaved[i].sequences.size() / 2
                assert tabs_part_2[i].rowCount == fastqs_merged[i].sequences.size()
            }
            
        }
    }

}
