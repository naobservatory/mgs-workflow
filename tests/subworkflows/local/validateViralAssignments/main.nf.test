nextflow_workflow {

    name "Test workflow VALIDATE_VIRAL_ASSIGNMENTS"
    script "subworkflows/local/validateViralAssignments/main.nf"
    workflow "VALIDATE_VIRAL_ASSIGNMENTS"
    config "tests/configs/downstream.config"
    tag "subworkflow"
    tag "downstream"
    tag "validate_viral_assignments"

    setup {
        run("LOAD_DOWNSTREAM_DATA") {
            script "subworkflows/local/loadDownstreamData/main.nf"
            process {
                """
                input[0] = "${projectDir}/test-data/downstream/input_file.csv"
                """
            }
        }
        run("PREPARE_GROUP_TSVS") {
            script "subworkflows/local/prepareGroupTsvs/main.nf"
            process {
                '''
                input[0] = LOAD_DOWNSTREAM_DATA.out.input
                '''
            }
        }
        run("COPY_FILE_BARE") {
            script "modules/local/copyFile/main.nf"
            process {
                '''
                input[0] = "${params.ref_dir}/results/total-virus-db-annotated.tsv.gz"
                input[1] = "virus-db.tsv.gz"
                '''
            }
        }
    }

    test("Should run without failures on valid input data") {
        tag "expect_success"
        when {
            params {
                n_clusters = 10
            }
            workflow {
                '''
                input[0] = PREPARE_GROUP_TSVS.out.groups
                input[1] = COPY_FILE_BARE.out
                input[2] = params.validation_cluster_identity
                input[3] = 15
                input[4] = params.n_clusters
                input[5] = false // not single-end
                '''
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Clustering should preserve reads
            def tabs_split = workflow.out.test_split_tsv.collect{path(it[1]).csv(sep: "\t",decompress: true)}
            def tabs_clust = workflow.out.test_cluster_tab.collect{path(it[1]).csv(sep: "\t",decompress: true)}
            assert tabs_split.size() == tabs_clust.size()
            for (int i = 0; i < tabs_split.size(); i++) {
                assert tabs_split[i].rowCount == tabs_clust[i].rowCount
            }
            // Regrouping should work as expected
            def tabs_in = workflow.out.test_in.collect{path(it[1]).csv(sep: "\t",decompress: true)}
            def tabs_regrouped = workflow.out.test_regrouped.collect{path(it[1]).csv(sep: "\t",decompress: true)}
            assert tabs_regrouped.size() == tabs_in.size()
            for (int i=0; i < tabs_regrouped.size(); i++) {
                assert tabs_regrouped[i].rowCount == tabs_in[i].rowCount
                assert tabs_regrouped[i].columns["seq_id"].unique().toSorted() == tabs_in[i].columns["seq_id"].unique().toSorted()
            }
        }
    }

}
